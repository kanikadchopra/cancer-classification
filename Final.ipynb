{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\n",
    "from keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_directory():\n",
    "    pwd = os.getcwd()\n",
    "    \n",
    "    os.mkdir(pwd+'/training')\n",
    "    os.mkdir(pwd+'/training/LUAD_TRAIN')\n",
    "    os.mkdir(pwd+'/training/LUSC_TRAIN')\n",
    "    os.mkdir(pwd+'/training/MESO_TRAIN')\n",
    "\n",
    "    \n",
    "    train_dir = '/kaggle/input/histopathology-dataset/train/'\n",
    "    cancers = [\"LUAD\",\"LUSC\",\"MESO\"]\n",
    "    luad_train_dir = '/kaggle/working/training/LUAD_TRAIN/'\n",
    "    lusc_train_dir = '/kaggle/working/training/LUSC_TRAIN/'\n",
    "    meso_train_dir = '/kaggle/working/training/MESO_TRAIN/'\n",
    "    cat_train_dir = [luad_train_dir,lusc_train_dir,meso_train_dir]\n",
    "\n",
    "    for i in range(3):\n",
    "        for f in glob.iglob(train_dir+cancers[i]+\"/*\"):\n",
    "            for subf in glob.iglob(f+'/*'):\n",
    "                shutil.copy(subf,cat_train_dir[i])\n",
    "    \n",
    "    labels = [\"LUAD\",\"LUSC\",\"MESO\"]\n",
    "    dir_label_df = pd.DataFrame(columns = [\"directory\",\"label\"])\n",
    "    for i in range(3):\n",
    "        filepaths_i = glob.glob(cat_train_dir[i]+\"/*\")\n",
    "        series_i = pd.Series(filepaths_i)\n",
    "        df_i = pd.DataFrame(series_i,columns = [\"directory\"])\n",
    "        df_i[\"label\"] = labels[i]\n",
    "        dir_label_df = pd.concat([dir_label_df,df_i],axis=0)\n",
    "    \n",
    "    return dir_label_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_directory():\n",
    "    \n",
    "    pwd = os.getcwd()\n",
    "    \n",
    "    os.mkdir(pwd+'/testing')\n",
    "    os.mkdir(pwd+'/testing/LUAD_TEST')\n",
    "    os.mkdir(pwd+'/testing/LUSC_TEST')\n",
    "    os.mkdir(pwd+'/testing/MESO_TEST')\n",
    "\n",
    "    test_dir = '/kaggle/input/histopathology-dataset/dev/'\n",
    "    cancers = [\"LUAD\",\"LUSC\",\"MESO\"]\n",
    "    luad_test_dir = '/kaggle/working/testing/LUAD_TEST/'\n",
    "    lusc_test_dir = '/kaggle/working/testing/LUSC_TEST/'\n",
    "    meso_test_dir = '/kaggle/working/testing/MESO_TEST/'\n",
    "    cat_test_dir = [luad_test_dir,lusc_test_dir,meso_test_dir]\n",
    "\n",
    "\n",
    "    for i in range(3):\n",
    "        for f in glob.iglob(test_dir+cancers[i]+\"/*\"):\n",
    "            for subf in glob.iglob(f+'/*'):\n",
    "                shutil.copy(subf,cat_test_dir[i])\n",
    "\n",
    "\n",
    "    labels = [\"LUAD\",\"LUSC\",\"MESO\"]\n",
    "    test_label_df = pd.DataFrame(columns = [\"directory\",\"label\"])\n",
    "    for i in range(3):\n",
    "        filepaths_i = glob.glob(cat_test_dir[i]+\"/*\")\n",
    "        series_i = pd.Series(filepaths_i)\n",
    "        df_i = pd.DataFrame(series_i,columns = [\"directory\"])\n",
    "        df_i[\"label\"] = labels[i]\n",
    "        test_label_df = pd.concat([test_label_df,df_i],axis=0)\n",
    "\n",
    "\n",
    "    test_label_df = test_label_df.reset_index(drop=True)\n",
    "    return test_label_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above moves pictures from input to output in the kaggle directory structure. We also saved the directory of every patch with its respective label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yushrajcoomar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/Users/yushrajcoomar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "dir_label_df = train_directory()\n",
    "test_label_df = test_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(dir_label_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train set shape: {train.shape}\")\n",
    "print(f\"test set shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.Resize((128,128)),\n",
    "     transforms.RandomApply([\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()],0.5),\n",
    "     transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augments the data with respect to our transformations listed above. MESO is augmented 25x and LUAD is augmented 2x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(train):\n",
    "    \n",
    "    aug_label_df = pd.DataFrame(columns = [\"directory\",\"label\"])\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        row = train.iloc[i]\n",
    "        row_directory = row['directory']\n",
    "        row_label = row['label']\n",
    "        \n",
    "        if row_label == \"LUAD\":\n",
    "            \n",
    "            for j in range(2):\n",
    "                img = load_img(row_directory)\n",
    "                trans_img = transform_train(img)\n",
    "                new_dir = row_directory[:-4] + '_' + str(j) + '.jpg'\n",
    "                save_img(new_dir,img_to_array(trans_img),data_format='channels_first')\n",
    "\n",
    "                series_i = pd.Series(new_dir)\n",
    "                df_i = pd.DataFrame(series_i, columns = [\"directory\"])\n",
    "                df_i[\"label\"] = \"LUAD\"\n",
    "                aug_label_df = pd.concat([aug_label_df,df_i],axis=0)\n",
    "                \n",
    "        if row_label == \"MESO\":\n",
    "            \n",
    "            for z in range(25):\n",
    "                \n",
    "                img = load_img(row_directory)\n",
    "                trans_img = transform_train(img)\n",
    "                new_dir = row_directory[:-4] + '_' + str(z) + '.jpg'\n",
    "                save_img(new_dir,img_to_array(trans_img),data_format='channels_first')\n",
    "\n",
    "                series_i = pd.Series(new_dir)\n",
    "                df_i = pd.DataFrame(series_i,columns = [\"directory\"])\n",
    "                df_i[\"label\"] = \"MESO\"\n",
    "                aug_label_df = pd.concat([aug_label_df,df_i],axis=0)\n",
    "                \n",
    "        else:\n",
    "            img = load_img(row_directory)\n",
    "            trans_img = transform_train(img)\n",
    "            new_dir = row_directory[:-4] + '_' + str(i) + '.jpg'\n",
    "            save_img(new_dir,img_to_array(trans_img),data_format='channels_first')\n",
    "\n",
    "            series_i = pd.Series(new_dir)\n",
    "            df_i = pd.DataFrame(series_i,columns = [\"directory\"])\n",
    "            df_i[\"label\"] = \"LUSC\"\n",
    "            aug_label_df = pd.concat([aug_label_df,df_i],axis=0)\n",
    "                \n",
    "        \n",
    "    return aug_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_augmentation(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for RGB to HSV optimization as a color mask. (which we dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "dir_img_rgb = dir_label_df.iloc[83]['directory']\n",
    "img_rbg = cv.imread(dir_img_rgb)\n",
    "plt.imshow(img_rbg)\n",
    "img_hsv = cv.cvtColor(img_rbg,cv.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([110,50,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "\n",
    "lower_red = np.array([150,135,100])\n",
    "upper_red = np.array([170,255,255])\n",
    "\n",
    "lower_notwhite = np.array([20,0,0])\n",
    "upper_notwhite = np.array([102,255,255])\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv.bitwise_and(img_rbg,img_rbg, mask= mask)\n",
    "\n",
    "plt.imshow(res)\n",
    "\n",
    "lower_red = np.array([150,135,0])\n",
    "upper_red = np.array([190,255,200])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "pos = 1\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        labels_i = labels[i]\n",
    "        index_i = dir_label_df[dir_label_df[\"label\"] == labels_i].index\n",
    "        random = np.random.randint(index_i[0],index_i[-1])\n",
    "        plt.subplot(3,5,pos)\n",
    "        pos+=1\n",
    "        img_rbg = cv2.imread(dir_label_df.loc[random,\"directory\"])\n",
    "        img_hsv = cv.cvtColor(img_rbg,cv.COLOR_BGR2HSV)\n",
    "        mask = cv.inRange(img_hsv, lower_red, upper_red)\n",
    "        res = cv.bitwise_and(img_rbg,img_rbg, mask= mask)\n",
    "        plt.imshow(res)\n",
    "        plt.title(dir_label_df.loc[random, \"label\"], size = 15, color = \"white\") \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./224.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/224.)\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(dataframe = train,\n",
    "                                              x_col = 'directory', y_col ='label',\n",
    "                                              target_size = (224,224), batch_size = 32, \n",
    "                                              class_mode = 'categorical', shuffle = True)\n",
    "test_gen = test_datagen.flow_from_dataframe(test,\n",
    "                                            target_size = (224,224), x_col = 'directory', y_col ='label',\n",
    "                                             class_mode = 'categorical',\n",
    "                                            batch_size = 16, shuffle = False)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1/224.)\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_dataframe(test_label_df,\n",
    "                                            target_size = (224,224), x_col = 'directory', y_col ='label',\n",
    "                                             class_mode = 'categorical',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(2, 2), activation = 'relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(256,(2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"cleaned_classififier.h5\", save_best_only=True, verbose = 0)]\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, validation_data = test_gen, use_multiprocessing=True, workers = 6, epochs=12, callbacks = callbacks, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "base_model = keras.applications.InceptionV3(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "x = keras.layers.Dense(256)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "outputs = keras.layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss',patience=2)]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, validation_data = test_gen,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6,\n",
    "                    epochs = 15,\n",
    "                    callbacks = callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_resnet = keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",  \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model_resnet.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model_resnet(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "x = keras.layers.Dense(256)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "outputs = keras.layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "model_resnet = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss',patience=4)]\n",
    "\n",
    "model_resnet.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_resnet.fit(train_gen, validation_data = test_gen,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6,\n",
    "                    epochs = 15,\n",
    "                    callbacks = callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_densenet = keras.applications.DenseNet121(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model_densenet.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model_densenet(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "x = keras.layers.Dense(256)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "outputs = keras.layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "model_densenet = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss',patience=4)]\n",
    "model_densenet.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_densenet.fit(train_gen, validation_data = test_gen,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6,\n",
    "                    epochs = 15,\n",
    "                    callbacks = callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_matrix(generator,model):\n",
    "    test_steps_per_epoch = np.math.ceil(generator.samples / generator.batch_size)\n",
    "    predictions = model.predict(generator,test_steps_per_epoch)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = generator.classes\n",
    "    class_labels = list(generator.class_indices.keys()) \n",
    "    \n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(report)\n",
    "    \n",
    "    conf_mat = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(conf_mat)\n",
    "    \n",
    "def model_metrics(generator,model):\n",
    "    test_steps_per_epoch = np.math.ceil(generator.samples / generator.batch_size)\n",
    "    predictions = model.predict(generator,test_steps_per_epoch)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = generator.classes\n",
    "    accuracy = accuracy_score(predicted_classes,true_classes)\n",
    "    precision = precision_score(predicted_classes,true_classes,average='weighted')\n",
    "    recall = recall_score(predicted_classes,true_classes,average='weighted')\n",
    "    f1 = f1_score(predicted_classes,true_classes,average='weighted')\n",
    "    \n",
    "    print(\"Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1: {}\".format(round(accuracy,4),\n",
    "                                                                   round(precision,4),\n",
    "                                                                   round(recall,4),\n",
    "                                                                   round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for models we ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics(test_gen,model)\n",
    "model_metrics(validation_gen,model)\n",
    "report_matrix(test_gen,model)\n",
    "report_matrix(validation_gen,model)\n",
    "\n",
    "\n",
    "model_metrics(test_gen,model_resnet)\n",
    "model_metrics(validation_gen,model_resnet)\n",
    "report_matrix(test_gen,model_resnet)\n",
    "report_matrix(validation_gen,model_resnet)\n",
    "\n",
    "\n",
    "model_metrics(test_gen,model_densenet)\n",
    "model_metrics(validation_gen,model_densenet)\n",
    "report_matrix(test_gen,model_densenet)\n",
    "report_matrix(validation_gen,model_densenet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
